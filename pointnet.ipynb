{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":1598438,"sourceType":"datasetVersion","datasetId":943153}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport shutil\nimport random\nfrom pathlib import Path\nimport wandb\n\nimport torch\nimport torch.nn as nn\nimport torchvision.transforms as transforms\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.amp import autocast, GradScaler\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nrandom.seed(42)\nnp.random.seed(42)\ntorch.manual_seed(42)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"src_root = \"/kaggle/input/modelnet10-princeton-3d-object-dataset/ModelNet10\"\ndst_root = \"/kaggle/working/ModelNet10\"\n\nos.makedirs(dst_root, exist_ok=True)\nrandom.seed(42)\n\nfor class_name in os.listdir(src_root):\n    class_path = os.path.join(src_root, class_name)\n    if not os.path.isdir(class_path):\n        continue\n\n    train_files = list(Path(class_path, \"train\").glob(\"*.off\"))\n    test_files = list(Path(class_path, \"test\").glob(\"*.off\"))\n    all_files = train_files + test_files\n    random.shuffle(all_files)\n\n    total = len(all_files)\n    train_split = int(0.8 * total)\n    val_split = int(0.1 * total)\n\n    train_set = all_files[:train_split]\n    val_set = all_files[train_split:train_split + val_split]\n    test_set = all_files[train_split + val_split:]\n\n    for subset, file_list in zip([\"train\", \"val\", \"test\"], [train_set, val_set, test_set]):\n        subset_dir = os.path.join(dst_root, class_name, subset)\n        os.makedirs(subset_dir, exist_ok=True)\n\n        for file_path in file_list:\n            shutil.copy(file_path, subset_dir)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-20T16:06:22.957028Z","iopub.execute_input":"2025-07-20T16:06:22.957268Z","iopub.status.idle":"2025-07-20T16:07:12.758364Z","shell.execute_reply.started":"2025-07-20T16:06:22.957250Z","shell.execute_reply":"2025-07-20T16:07:12.757802Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"class PointNetDataset(Dataset):\n    def __init__(self, base_path='/kaggle/working/ModelNet10', mode='train', n_points=1024):\n        super().__init__()\n        self.n_points = n_points\n        self.base_path = base_path\n        self.mode = mode\n        self.class_idx = {'bathtub': 0, 'bed': 1, 'chair': 2, 'desk': 3, 'dresser': 4,\n                          'monitor': 5,'night_stand': 6, 'sofa': 7, 'table': 8, 'toilet': 9}\n\n        self.samples = []\n        self._prepare_dataset()\n\n    def _prepare_dataset(self):\n        for class_name in os.listdir(self.base_path):\n            if class_name not in self.class_idx:\n                continue\n                \n            class_id = self.class_idx[class_name]\n            \n            class_path = os.path.join(self.base_path, class_name, self.mode)\n            for file in os.listdir(class_path):\n                file_path = os.path.join(class_path, file)\n\n                with open(file_path, 'r') as f:\n                    lines = f.readlines()\n                parts = lines[1].strip().split()\n                verts = []\n\n                num_verts = int(parts[0])\n                for i in range(2, 2 + num_verts):\n                    verts.append(list(map(float, lines[i].strip().split())))\n\n                verts = self._normalize_point_cloud(verts)\n                verts = self._sample_point_cloud(verts, self.n_points)\n\n                self.samples.append((verts, class_id))\n\n    def _normalize_point_cloud(self, verts):\n        verts = np.array(verts)\n        centroid = np.mean(verts, axis=0)\n        verts = verts - centroid\n        furthest_distance = np.max(np.linalg.norm(verts, axis=1))\n        verts = verts / furthest_distance\n        return verts\n\n    def _sample_point_cloud(self, verts, n_points):\n        return verts[np.random.choice(len(verts), n_points, replace=(len(verts) < n_points))]\n\n    def __len__(self):\n        return len(self.samples)\n\n    def __getitem__(self, idx):\n        verts, label = self.samples[idx]\n\n        if self.mode == 'train':\n            verts = verts[np.random.permutation(len(verts))]\n        \n        verts = torch.tensor(verts, dtype=torch.float32)\n        label = torch.tensor(label, dtype=torch.long)\n        return verts, label","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-20T16:07:12.759442Z","iopub.execute_input":"2025-07-20T16:07:12.759687Z","iopub.status.idle":"2025-07-20T16:07:12.768794Z","shell.execute_reply.started":"2025-07-20T16:07:12.759663Z","shell.execute_reply":"2025-07-20T16:07:12.768311Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"train_set = PointNetDataset(mode='train')\nval_set = PointNetDataset(mode='val')\ntest_set = PointNetDataset(mode='test')\n\ntrain_loader = DataLoader(train_set, batch_size=32, shuffle=True, num_workers=2)\nval_loader = DataLoader(val_set, batch_size=32, shuffle=False, num_workers=2)\ntest_loader = DataLoader(test_set, batch_size=32, shuffle=False, num_workers=2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-20T16:07:12.769599Z","iopub.execute_input":"2025-07-20T16:07:12.769849Z","iopub.status.idle":"2025-07-20T16:09:09.745527Z","shell.execute_reply.started":"2025-07-20T16:07:12.769825Z","shell.execute_reply":"2025-07-20T16:09:09.744637Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"class InputTNet(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.shared_mlp = nn.Sequential(\n            nn.Conv1d(3, 64, 1),\n            nn.BatchNorm1d(64),\n            nn.ReLU(),\n            nn.Conv1d(64, 128, 1),\n            nn.BatchNorm1d(128),\n            nn.ReLU(),\n            nn.Conv1d(128, 1024, 1),\n            nn.BatchNorm1d(1024),\n            nn.ReLU()\n        )\n        self.fc = nn.Sequential(\n            nn.Linear(1024, 512),\n            nn.Linear(512, 256),\n            nn.Linear(256, 9)\n        )\n\n        nn.init.constant_(self.fc[2].weight, 0)\n        identity = torch.eye(3).view(9)\n        nn.init.constant_(self.fc[2].bias, 0)\n        with torch.no_grad():\n            self.fc[2].bias.copy_(identity)\n\n    def forward(self, x):\n        batch_sz = x.shape[0]\n        out = x.transpose(1, 2) # (B, 3, N)\n        out = self.shared_mlp(out) # (B, 1024, N)\n        out = torch.max(out, dim=2)[0] # (B, 1024)\n        out = self.fc(out) # (B, 9)\n        out = out.reshape(batch_sz, 3, -1) # (B, 3, 3)\n        return out","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class FeatureTNet(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.shared_mlp = nn.Sequential(\n            nn.Conv1d(64, 128, 1),\n            nn.BatchNorm1d(128),\n            nn.ReLU(),\n            nn.Conv1d(128, 1024, 1),\n            nn.BatchNorm1d(1024),\n            nn.ReLU()\n        )\n        self.fc = nn.Sequential(\n            nn.Linear(1024, 512),\n            nn.Linear(512, 256),\n            nn.Linear(256, 4096)\n        )\n\n        nn.init.constant_(self.fc[2].weight, 0)\n        identity = torch.eye(64).view(4096)\n        nn.init.constant_(self.fc[2].bias, 0)\n        with torch.no_grad():\n            self.fc[2].bias.copy_(identity)\n\n    def forward(self, x):\n        batch_sz = x.shape[0]\n        out = x.transpose(1, 2) # (B, 64, N)\n        out = self.shared_mlp(out) # (B, 1024, N)\n        out = torch.max(out, dim=2)[0] # (B, 1024)\n        out = self.fc(out) # (B, 4096)\n        out = out.reshape(batch_sz, 64, -1) # (B, 64, 64)\n        return out","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class PointNetClassifier(nn.Module):\n\n    def __init__(self, num_classes=10):\n        super().__init__()\n        self.input_tnet = InputTNet()\n        self.shared_mlp = nn.Sequential(\n            nn.Conv1d(3, 64, 1),\n            nn.BatchNorm1d(64),\n            nn.ReLU(),\n            nn.Conv1d(64, 64, 1),\n            nn.BatchNorm1d(64),\n            nn.ReLU(),\n        )\n        self.feature_tnet = FeatureTNet()\n        self.shared_mlp_2 = nn.Sequential(\n            nn.Conv1d(64, 64, 1),\n            nn.BatchNorm1d(64),\n            nn.ReLU(),\n            nn.Conv1d(64, 128, 1),\n            nn.BatchNorm1d(128),\n            nn.ReLU(),\n            nn.Conv1d(128, 1024, 1),\n            nn.BatchNorm1d(1024),\n            nn.ReLU(),\n        )\n        self.fc = nn.Sequential(\n            nn.Linear(1024, 512),\n            nn.BatchNorm1d(512),\n            nn.ReLU(),\n        \n            nn.Linear(512, 256),\n            nn.BatchNorm1d(256),\n            nn.ReLU(),\n            nn.Dropout(p=0.3),\n        \n            nn.Linear(256, num_classes)\n        )\n\n    def forward(self, x):\n        input_trans = self.input_tnet(x) # (B, 3, 3)\n        out = torch.bmm(x, input_trans) # (B, N, 3) * (B, 3, 3) = (B, N, 3)\n        out = out.transpose(1, 2) # (B, 3, N)\n        out = self.shared_mlp(out) # (B, 64, N)\n        out = out.transpose(1, 2) # (B, N, 64)\n        feature_trans = self.feature_tnet(out) # (B, 64, 64)\n        out = torch.bmm(out, feature_trans) # (B, N, 64) * (B, 64, 64) = (B, N, 64)\n        out = out.transpose(1, 2) # (B, 64, N)\n        out = self.shared_mlp_2(out) # (B, 1024, N)\n        out = torch.max(out, dim=2)[0] # (B, 1024)\n        out = self.fc(out) # (B, num_classes)\n        return out, input_trans, feature_trans","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-20T16:09:09.746998Z","iopub.execute_input":"2025-07-20T16:09:09.747207Z","iopub.status.idle":"2025-07-20T16:09:09.760730Z","shell.execute_reply.started":"2025-07-20T16:09:09.747191Z","shell.execute_reply":"2025-07-20T16:09:09.759958Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"class PointNetSegmentation(nn.Module):\n    \n    def __init__(self, num_classes=10):\n        super().__init__()\n        self.input_tnet = InputTNet()\n        self.shared_mlp = nn.Sequential(\n            nn.Conv1d(3, 64, 1),\n            nn.BatchNorm1d(64),\n            nn.ReLU(),\n            nn.Conv1d(64, 64, 1),\n            nn.BatchNorm1d(64),\n            nn.ReLU(),\n        )\n        self.feature_tnet = FeatureTNet()\n        self.shared_mlp_2 = nn.Sequential(\n            nn.Conv1d(64, 64, 1),\n            nn.BatchNorm1d(64),\n            nn.ReLU(),\n            nn.Conv1d(64, 128, 1),\n            nn.BatchNorm1d(128),\n            nn.ReLU(),\n            nn.Conv1d(128, 1024, 1),\n            nn.BatchNorm1d(1024),\n            nn.ReLU(),\n        )\n        self.seg_mlp = nn.Sequential(\n            nn.Conv1d(1088, 512, 1),\n            nn.BatchNorm1d(512),\n            nn.ReLU(),\n        \n            nn.Conv1d(512, 256, 1),\n            nn.BatchNorm1d(256),\n            nn.ReLU(),\n            \n            nn.Conv1d(256, 128, 1),\n            nn.BatchNorm1d(128),\n            nn.ReLU(),\n        \n            nn.Conv1d(128, num_classes, 1)\n        )\n\n    def forward(self, x):\n        input_trans = self.input_tnet(x) # (B, 3, 3)\n        out = torch.bmm(x, input_trans) # (B, N, 3) * (B, 3, 3) = (B, N, 3)\n        out = out.transpose(1, 2) # (B, 3, N)\n        out = self.shared_mlp(out) # (B, 64, N)\n        out = out.transpose(1, 2) # (B, N, 64)\n        feature_trans = self.feature_tnet(out) # (B, 64, 64)\n        feature_out = torch.bmm(out, feature_trans) # (B, N, 64) * (B, 64, 64) = (B, N, 64)\n        feature_out = feature_out.transpose(1, 2) # (B, 64, N)\n        out = self.shared_mlp_2(feature_out) # (B, 1024, N)\n        out = torch.cat((feature_out, out), dim=1) # (B, 1088, N)\n        out = self.seg_mlp(out) # (B, num_classes, N)\n        out = out.transpose(1, 2) # (B, N, num_classes)\n        return out, input_trans, feature_trans","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def orthogonality_loss(trans):\n    batch_size, k, _ = trans.size()\n    I = torch.eye(k, device=trans.device).unsqueeze(0).expand(batch_size, -1, -1)\n    trans_transpose = trans.transpose(2, 1)\n    prod = torch.bmm(trans, trans_transpose)\n    diff = prod - I # (B, k, k)\n    return torch.mean(torch.norm(diff, dim=(1, 2)))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-20T16:09:09.761335Z","iopub.execute_input":"2025-07-20T16:09:09.761578Z","iopub.status.idle":"2025-07-20T16:09:09.776581Z","shell.execute_reply.started":"2025-07-20T16:09:09.761561Z","shell.execute_reply":"2025-07-20T16:09:09.775991Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"import wandb\nfrom tqdm.notebook import tqdm\n\nwandb.init(project=\"pointnet-classification\")\n\nmodel = PointNetClassifier().to(device)\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n\nbest_val_loss = float(\"inf\")\npatience = 3\npatience_counter = 0\nnum_epochs = 20\n\nfor epoch in range(num_epochs):\n    model.train()\n    train_loss, train_total = 0.0, 0\n\n    # Training loop with tqdm progress bar\n    train_loader_tqdm = tqdm(train_loader, desc=f\"[Epoch {epoch+1}] Training\")\n    for verts, labels in train_loader_tqdm:\n        verts, labels = verts.to(device), labels.to(device)\n        out, input_trans, feature_trans = model(verts)\n\n        cls_loss = F.cross_entropy(out, labels)\n        inp_trans_loss = orthogonality_loss(input_trans)\n        feat_trans_loss = orthogonality_loss(feature_trans)\n        loss = cls_loss + 0.001 * (inp_trans_loss + feat_trans_loss)\n\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        batch_size = verts.size(0)\n        train_loss += loss.item() * batch_size\n        train_total += batch_size\n\n        # Update tqdm bar with current batch loss\n        train_loader_tqdm.set_postfix(batch_loss=loss.item())\n\n    avg_train_loss = train_loss / train_total\n\n    model.eval()\n    val_loss, val_total = 0.0, 0\n\n    # Validation loop with tqdm\n    val_loader_tqdm = tqdm(val_loader, desc=f\"[Epoch {epoch+1}] Validation\")\n    with torch.no_grad():\n        for verts, labels in val_loader_tqdm:\n            verts, labels = verts.to(device), labels.to(device)\n            out, input_trans, feature_trans = model(verts)\n\n            cls_loss = F.cross_entropy(out, labels)\n            inp_trans_loss = orthogonality_loss(input_trans)\n            feat_trans_loss = orthogonality_loss(feature_trans)\n            loss = cls_loss + 0.001 * (inp_trans_loss + feat_trans_loss)\n\n            batch_size = verts.size(0)\n            val_loss += loss.item() * batch_size\n            val_total += batch_size\n\n            val_loader_tqdm.set_postfix(batch_loss=loss.item())\n\n    avg_val_loss = val_loss / val_total\n\n    # Log to Weights & Biases\n    wandb.log({\n        \"epoch\": epoch,\n        \"train_loss\": avg_train_loss,\n        \"val_loss\": avg_val_loss\n    })\n\n    # Print epoch summary\n    print(f\"[Epoch {epoch+1}] Train Loss: {avg_train_loss:.4f} | Val Loss: {avg_val_loss:.4f}\")\n\n    # Early stopping logic\n    if avg_val_loss < best_val_loss:\n        best_val_loss = avg_val_loss\n        patience_counter = 0\n        torch.save(model.state_dict(), \"pointnet_classifier.pth\")\n    else:\n        patience_counter += 1\n        if patience_counter >= patience:\n            print(f\"Early stopping at epoch {epoch+1}\")\n            break","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}